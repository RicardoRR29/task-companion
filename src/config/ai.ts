// src/config/ai.ts

/**
 * Configura√ß√µes centralizadas para integra√ß√£o com IA
 */
export const AI_CONFIG = {
  // Modelo de IA a ser utilizado (com fallback autom√°tico)
  MODEL: "gpt-5-mini",

  // URL da API OpenAI
  API_URL: "https://api.openai.com/v1/chat/completions",

  // Configura√ß√µes padr√£o para as requisi√ß√µes
  DEFAULT_OPTIONS: {
    temperature: 0.7,
    max_tokens: 4000,
    function_call: "auto" as const,
  },

  // Chave da API (deve ser definida em .env)
  get API_KEY() {
    const key = import.meta.env.VITE_OPENAI_API_KEY;
    if (!key) {
      console.error("‚ùå VITE_OPENAI_API_KEY n√£o encontrada no arquivo .env");
      return null;
    }

    // Valida formato da chave (deve come√ßar com 'sk-')
    if (!key.startsWith("sk-")) {
      console.error(
        "‚ùå Formato inv√°lido da chave da API. Deve come√ßar com 'sk-'"
      );
      return null;
    }

    return key;
  },

  // Verifica se a chave da API est√° configurada
  get isConfigured() {
    return !!this.API_KEY;
  },

  // Valida se a chave da API √© v√°lida
  get isValidKey() {
    const key = this.API_KEY;
    return key && key.startsWith("sk-") && key.length > 20;
  },
} as const;

/**
 * Tipos de modelos dispon√≠veis
 */
export const AI_MODELS = {
  GPT_5_MINI: "gpt-5-mini",
  GPT_5: "gpt-5",
  GPT_5_NANO: "gpt-5-nano",
  GPT_4O_MINI: "gpt-4o-mini",
  GPT_4O: "gpt-4o",
  GPT_4_TURBO: "gpt-4-turbo-preview",
  GPT_3_5_TURBO: "gpt-3.5-turbo",
} as const;

export type AIModel = (typeof AI_MODELS)[keyof typeof AI_MODELS];

/**
 * Lista de modelos em ordem de prefer√™ncia (fallback autom√°tico)
 */
export const MODEL_FALLBACK_ORDER = [
  AI_MODELS.GPT_5_MINI,
  AI_MODELS.GPT_4O_MINI,
  AI_MODELS.GPT_3_5_TURBO,
] as const;

/**
 * Verifica se um modelo est√° dispon√≠vel
 */
export async function checkModelAvailability(model: string): Promise<boolean> {
  try {
    // Verifica se a chave est√° configurada antes de fazer a requisi√ß√£o
    if (!AI_CONFIG.isValidKey) {
      console.error("‚ùå Chave da API n√£o configurada ou inv√°lida");
      return false;
    }

    const response = await fetch(
      `${AI_CONFIG.API_URL.replace("/chat/completions", "")}/models`,
      {
        headers: {
          Authorization: `Bearer ${AI_CONFIG.API_KEY}`,
        },
      }
    );

    if (!response.ok) {
      if (response.status === 401) {
        console.error(
          "‚ùå Erro de autentica√ß√£o: Chave da API inv√°lida ou expirada"
        );
      } else if (response.status === 403) {
        console.error(
          "‚ùå Erro de permiss√£o: Chave da API n√£o tem acesso a este endpoint"
        );
      } else {
        console.error(
          `‚ùå Erro na verifica√ß√£o de modelos: ${response.status} ${response.statusText}`
        );
      }
      return false;
    }

    const data = await response.json();
    return data.data?.some((m: { id: string }) => m.id === model) ?? false;
  } catch (error) {
    console.error("‚ùå Erro ao verificar disponibilidade do modelo:", error);
    return false;
  }
}

/**
 * Obt√©m o primeiro modelo dispon√≠vel da lista de fallback
 */
export async function getAvailableModel(): Promise<string> {
  // Verifica se a chave est√° configurada
  if (!AI_CONFIG.isValidKey) {
    console.error("‚ùå Chave da API n√£o configurada ou inv√°lida");
    throw new Error("Chave da API n√£o configurada ou inv√°lida");
  }

  for (const model of MODEL_FALLBACK_ORDER) {
    if (await checkModelAvailability(model)) {
      console.log(`‚úÖ Modelo ${model} est√° dispon√≠vel`);
      return model;
    }
  }

  // Fallback para GPT-3.5 Turbo (geralmente sempre dispon√≠vel)
  console.log("‚ö†Ô∏è Usando GPT-3.5 Turbo como fallback");
  return AI_MODELS.GPT_3_5_TURBO;
}

/**
 * Configura√ß√£o din√¢mica baseada na disponibilidade dos modelos
 */
export const DYNAMIC_AI_CONFIG = {
  async getModel() {
    return await getAvailableModel();
  },

  async getConfig() {
    const model = await this.getModel();
    return {
      ...AI_CONFIG,
      MODEL: model,
    };
  },

  // Valida a configura√ß√£o completa
  validateConfig() {
    if (!AI_CONFIG.isValidKey) {
      throw new Error("Chave da API n√£o configurada ou inv√°lida");
    }
    return true;
  },
} as const;

/**
 * Utilit√°rios para debug e troubleshooting
 */
export const AI_DEBUG = {
  // Verifica o status da configura√ß√£o
  checkStatus() {
    const status = {
      hasKey: !!AI_CONFIG.API_KEY,
      isValidKey: AI_CONFIG.isValidKey,
      isConfigured: AI_CONFIG.isConfigured,
      keyPrefix: AI_CONFIG.API_KEY?.substring(0, 7) || "N/A",
      keyLength: AI_CONFIG.API_KEY?.length || 0,
    };

    console.log("üîç Status da configura√ß√£o de IA:", status);
    return status;
  },

  // Testa a conex√£o com a API
  async testConnection() {
    try {
      if (!AI_CONFIG.isValidKey) {
        throw new Error("Chave da API n√£o configurada");
      }

      const response = await fetch(
        `${AI_CONFIG.API_URL.replace("/chat/completions", "")}/models`,
        {
          headers: {
            Authorization: `Bearer ${AI_CONFIG.API_KEY}`,
          },
        }
      );

      if (response.ok) {
        console.log("‚úÖ Conex√£o com a API OpenAI estabelecida com sucesso");
        return true;
      } else {
        console.error(
          `‚ùå Erro na conex√£o: ${response.status} ${response.statusText}`
        );
        return false;
      }
    } catch (error) {
      console.error("‚ùå Erro ao testar conex√£o:", error);
      return false;
    }
  },
} as const;
